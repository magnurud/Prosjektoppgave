% Chapter 3 - IMPLEMENTATION 

\chapter{Implementation} % Main chapter title

\label{chap:Implementation} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 3. \emph{Implementation details}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------

All implementation have been done in two dimensions on the unit square $(0,1)^2$. The goal of the implementation has been to show the strengths of the least-squares method. It is implemented with finite element and spectral basis functions and is compared to the results from standard Galerkin formulation. Finally the combined GLS-method described in chapter \ref{chap:newTheory} is also tested against the separate methods. The problems solved are simply expansions of the Poisson problem (All problems have belonging Dirichlet boundary contitions). 
\begin{align}
	-\Delta u = f \text{  in  } \Omega
	\label{eq:PossionImplementation}
\end{align}
Then by adding a transport term you obtain the diffusion transport equation
\begin{align}
	-\mu \Delta u + \mathbf{b} \cdot \nabla u = f \text{ in } \Omega
	\label{eq:DiffTransImplementation}
\end{align}
This can be further expanded by adding a reaction term
\begin{align}
	-\mu \Delta u + \mathbf{b} \cdot \nabla u +\sigma u = f \text{ in } \Omega
	\label{eq:ReactionImplementation}
\end{align}
And as a final complication the vector field $\mathbf{b}$ can be made dependent on $u$ and hence give us the nonlinear diffusion transport reaction equation
\begin{align}
	-\mu \Delta u + \mathbf{b}(u) \cdot \nabla u +\sigma u = f \text{ in } \Omega
	\label{eq:ReactionImplementation}
\end{align}

\section{The bilinear form obtained from least-squares}
 For the general problem\eref{eq:BVP} the functional $Q$ will take the form 
\begin{align}
	Q(u,v)=\int_{\Omega}(\mathcal{L}v)^T(\mathcal{L}u)d\Omega.
	\label{eq:functionalInt}
\end{align}
Implementing $Q$ requires two sets of basis functions $\{N_i\}$ that describes the search and solution space. In this project assignment the search and solution space will be described by the same set of basis functions which will depend on the method applied. $u$ is discretized as 
\begin{align}
	u_h = \sum_{I=0}^{K}a_IN_I.
	\label{eq:uDisc}
\end{align}
Where $K$ denotes the number of discretization points, which is the same as the number of basis functions. \colorbox{yellow}{Is this statement OK?} Since equation\eref{eq:varFormGen} requires equality for all test functions in the search space we simply solve it for each basis function. We are therefore left with a system of $K$ equations. Equation\eref{eq:functionalInt} can then be written for each test function as  
\begin{align}
	Q(u_h,N_I) &= \int_{\Omega}(\mathcal{L}N_I)^T(\mathcal{L}u_h)d\Omega \\
	&= \int_{\Omega}(\mathcal{L}N_I)^T(\mathcal{L}\sum_{J=1}^Ka_JN_J)d\Omega \\
	&= \sum_{J=1}^K\int_{\Omega}(\mathcal{L}N_I)^T(\mathcal{L}a_JN_J)d\Omega \\
	&= \sum_{J=1}^K\int_{\Omega}(\mathcal{L}N_I)^T(\mathcal{L}a_JN_J)d\Omega \\
	&= \sum_{J=1}^K\int_{\Omega}(\mathcal{L}N_I)^T(\mathcal{L}N_J)d\Omega \;\cdot a_J.
	\label{eq:varFormDisc}
\end{align}
The total system of equation for all test functions can then be written as a matrix equation 
\begin{align}
	Au = F.
	\label{eq:matrixEq}
\end{align}
Where $A^{LS}_{I,J}=\int_{\Omega}(\mathcal{L}N_I)^T(\mathcal{L}N_J)d\Omega$. Written explicitly for the Poisson and diffusion transport equations it will be a 3-by-3 matrix on the form 

$
A^{LS}_{I,J} = \int_{\Omega}
\begin{bmatrix}
	N_IN_J + \partial_x N_{I} \partial_xN_{J} & \partial_x N_{I}\partial_y N_{J} & N_IN_{J,x} \\ 	
	\partial_yN_{I}\partial_xN_{J} &N_IN_J + \partial_yN_{I}\partial_yN_{J} &  N_IN_{J,y} \\ 	
	N_{I,x}N_J & N_{I,y}N_J & N_{I,x}N_{J,x} + N_{I,y}N_{J,y} \\ 	
	\label{mat:basicPoisson}
\end{bmatrix}
d\Omega
$
where $\partial_x = \partial / \partial x $ for the Poisson problem and $\mu \partial / \partial x - b_1$ for the diffusion transport problem. Similarly $F_I$ will be given as 
\begin{align}
	F_I = \int_{\Omega}(\mathcal{L}N_I)^T\vec{f} d\Omega = 
	\int_{\Omega}
\begin{bmatrix}
	\partial_xN_I \\
	\partial_xN_I \\
	0
\end{bmatrix}
	f d\Omega
	\label{eq:rhsFunctional}
\end{align}

Notice that by doing the splitting of variables we obtain a system of equations three times as big as if we were to solve the equation directly. 

\section{LSFEM for Poisson}
\colorbox{yellow}{finite element space $X_h^1$ ? quadrature\ldots  }
\section{LS spectral method for Poisson}

The spectral implementation is done using Gauss Lobatto nodes and quadrature and the lagrange functions based on the GL nodes as basis functions. 
Notice that the discrete solution $u_h$ consist of the discretization of both $u \text{ and } w = - \nabla u$. $u_h$ can be structured block wise or node wise. By choosing a block wise representation the final system of equations can be written as 

$
\begin{bmatrix}
	A_{1,1} & A_{1,2} &	A_{1,3} \\ 	
	A_{2,1} & A_{2,2} & A_{2,3} \\ 	
	A_{3,1} & A_{3,2} & A_{3,3} \\ 	
\end{bmatrix}
\begin{bmatrix}
 u^h \\ 	
 w^h_1\\ 	
 w^h_2\\ 	
\end{bmatrix}
=
\begin{bmatrix}
 F_1 \\ 	
 F_2\\ 	
 0 \\ 	
\end{bmatrix}
$.

Where each block $A_{m,n}$ corresponds to  calculating element $m,n$ in the matrix~\ref{mat:basicPoisson} for all combinations of $I,J$. Let us take a closer look at element $A_{1,3}$ in order to achieve a more compact notation. 
\begin{align}
	(A_{1,3})_{I,J} &= \int_{\Omega} N_I N_{J,x} d\Omega \\
	&= \int_{\Omega} l_i(x)l_j(y)l'_k(x)l_l(y) d\Omega \\
	&= \sum_{\alpha}\sum_{\beta} w_{\alpha}w_{\beta}l_i(x_{\alpha})l_j(y_{\beta})l'_k(x_{\alpha})l_l(y_{\beta}).
	\label{eq:MatrixDerivation}
\end{align}
The sum is obtained by using Gauss Lobatto quadrature rule. Now notice that the lagrange polynomials $l_j(y_{\beta})$ are non-zero only when $\beta = j$, this implies that for the sum to exist we have to require $\beta = j=l$, and $\alpha = i$. With these considerations the double sum above simplifies to  
\begin{align}
	(A_{1,3})_{I,J} &= w_{i}w_{j}l'_k(x_{i})
	\label{eq:MatrixDerivation2}
\end{align}
Remember that $I = i+jN$ and $J = k+lN$, with $N$ being the number of nodes in each direction. This means that $A_{1,3}$ will consist of blocks where $i$ and $k$ goes from $1$ to $N$ while $j$ and $k$ are constant within each block. Since we require that $j=k$ we can immediately conclude that $A_{1,3}$ is nonzero only in the blocks along the diagonal. Notice that the factor $w_il'_k(x_i)$ is the same for each block, and it can be written in matrix form as $WL$, where $W$ is the $n \times n$ diagonal matrix with the GLL-weights along the diagonal and the $(L)_{i,j}= l_j'(x_i)$ is the matrix containing the derivatives of the lagrange polynomials. Since each block is multiplied with $w_j$ the whole matrix can simply be written as the Kronecker tensor product $(W\otimes WL)$. Similar reasoning can be made with all the other block matrices $A_{m,n}$ and we end up with a matrix on the form
%In order to implement this matrix it is convenient to write it in a compact form using the Kronecker tensor product. The components needed for this formulation is the $n \times n$ diagonal matrix $ W $ with the GLL-weigths along the diagonal and the $n \times n$ matrix $(L)_{i,j}= l_j'(x_i)$ where $l_j$ is the jth lagrange polynomial and $x_i$ is the ith node in either x or y direction. Note that the formulation is based on a grid of GLL-nodes in both x and y direction. 

%
$
A^{LS} = 
\begin{bmatrix}
	W \otimes (L^TWL+W) & WL \otimes L^TW 		 &	W \otimes WL  \\ 	
	L^TW \otimes WL     & (L^TWL+W) \otimes W  &	WL \otimes W  \\ 	
	W \otimes L^TW		  & L^TW \otimes W       &  L^TWL \otimes W +	W\otimes L^TWL  \\ 	
\end{bmatrix}
$

Note that without the reformulation of the PDE as a first order system and with regular Galerkin formulation the stiffness matrix will simply be 
$A_{3,3} = W \otimes L^TWL+ L^TWL \otimes W$.
\section{LS spectral method for Diffusion transport}
The matrix corresponding to the discretized variational formulation can be divided into two parts where one depends on $\mu$ alone and the other one contains the contributions from the gradient term in the original equation. 

$
A^{LS} = 
\begin{bmatrix}
	W \otimes (\mu L^TWL+W) & \mu WL \otimes L^TW 		 &	W \otimes WL  \\ 	
	\mu L^TW \otimes WL     & (\mu L^TWL+W) \otimes W  &	WL \otimes W  \\ 	
	W \otimes L^TW		  & L^TW \otimes W       &  L^TWL \otimes W +	W\otimes L^TWL  \\ 	
\end{bmatrix}
$

in addition it will be added some extra terms dependent on $b$ to the upper left $2 \times 2$ block matrix. Let $B_1$ and $B_2$ be diagonal $n^2 \times n^2$ matrices with the values of the first and second component of $b$ evaluated in each spacial node along the diagonal.  

\begin{align}
	G_{1,1} &= -\mu B_1 (W \otimes WL) -\mu( W \otimes L^TW) B_1 + B_1( W\otimes W) B_1 \\ 	
	G_{1,2} &= -\mu B_2 (W \otimes WL) -\mu (L^TW \otimes W) B_1 + B_1 (W\otimes W) B_2 \\
	G_{2,1} &= G_{1,2}^T \\
	G_{2,2} &= -\mu B_2 (WL \otimes W) -\mu (L^TW \otimes W) B_2 + B_2 (W\otimes W) B_2. 
	\label{eq:additionalMatrixDiffTrans}
\end{align}
%
We can then define the total matrix for the diffusion transport problem $K^{LS}$ as
\begin{align}
K^{LS} = A^{LS} + G^{LS}
	\label{eq:difftransMatrixSum}
\end{align}
Where $G^{LS}$ is the matrix given as 
$
G^{LS}=
\begin{bmatrix}
	G_{11} & G_{12} &0 \\
	G_{21} & G_{22} &0 \\
	0 & 0 & 0 
\end{bmatrix}.
$
%

Adding the gradient term in our equation also affects the loading function. In a compact notation the discretized loading vector from the variational formulation can be written as
$
F^{LS}=
\begin{bmatrix}
	\mu(W \otimes L^T W)F - (W \otimes W)B_1F \\
	\mu(L^TW \otimes W)F - (W \otimes W)B_2F \\
	0 & 
	\label{mat:FLS}
\end{bmatrix},
$
where $F$ is the vector with the loading function evaluated in each spacial node.
%
\section{non-linear diffusion transport problem}
The stepwise algorithm to solve the nonlinear equation is described in chapter~\ref{chap:newTheory}. However there are several computational steps that needs to be taken care of, both with regular Galerkin and least squares. In both cases we obtain two matrices which we will name $A$ and $G$ and with superscript LS if they refer to the least squares formulation. In both cases only $G$ will depend on the numerical solution $u_h$. An important difference however is that in the LS setting the $F$ vector will depend on $u_h$ while in the straight forward Galerkin setting it will not. For regular Galerkin spectral approach we obtain
%
\begin{align}
	A \tilde{u} + AR_g  + G(\tilde{u}+R_g)(\tilde{u}+R_g) -F = 0
\end{align}
Notice that for each iteration the matrix $G(\tilde{u}+R_g)$ needs to be evaluated, the homogeneous boundary conditions on $\tilde{u}$ needs to be imposed and the Jacobian needs to be calculated. The Jacobian $\mathcal{F}$ will for this setting be given as
%
\begin{align}
	\mathcal{J}_{i,j} = A_{i,j} + G(\tilde{u}+R_g)_{i,j} +  (\tilde{u}+R_g)_i \; \frac{\partial}{\partial \tilde{u}_j} (G(\tilde{u}+R_g))_i.
\end{align}
%
With the LS formulation we obtain
\begin{align}
A^{LS}\tilde{u} + A^{LS}R_g  + G^{LS}(\tilde{u}+R_g)(\tilde{u}+R_g) -F^{LS}(\tilde{u}+R_g) = 0\\
A^{LS}\tilde{u} + A^{LS}R_g  + G^{LS}(\tilde{u}+R_g)\tilde{u} -F^{LS}(\tilde{u}+R_g) = 0
\end{align}
It is clear from this equation that the term surging from the loading function also needs to be handled when calculating the Jacobian. The lifting function $R_g$ does only have nonzero values in the third "block", hence it belongs to the kernel of the $G$-matrix.

\begin{align}
	\mathcal{J}_{i,j} = A_{i,j} + G(\tilde{u}+R_g)_{i,j} +  [\frac{\partial}{\partial \tilde{u}_j} (G(\tilde{u}+R_g))_{i,:}] \tilde{u} \; - \frac{\partial}{\partial \tilde{u}_j}F(\tilde{u}+R_g)_i.
\end{align}
%
Let us first consider the $F$-vector. The terms are given in equation~\ref{mat:FLS} and it is clear that only the last terms in each block depends on $u$, notice that it does not depend on the components of the gradient $[ w_1 \; w_2]$. Hence the contribution to the total Jacobi matrix will only be in block $(1,3)$ and $(2,3)$. Further since $B_1$ and $B_2$ are both diagonal matrices where $B_{i,i}(u) = B_{i,i}(u_i)$ the Jacobian can be calculated efficiently by creating the matrices $dB_1$ and $dB_2$ which has the partial derivative of $B_1,B_2$ wrt. $u$ evaluated in each node.   



%The GLS-formulation is created simply by adding the variational formulation from the standard Galerkin and LS approach. By dividing the matrix surging from the bilinear functional into a linear and a non-linear part the system of equation can be written as 
%%
%\begin{align}
	%(A^{LS}+A)\mathbf{u_h} = -(G^{LS}(\mathbf{u_h})+G(\mathbf{u_h}))\mathbf{u_h} + f_h^{LS}(\mathbf{u_h})+f_h. \\
	%\mathcal{A} \mathbf{u_h} = \mathcal{F} (\mathbf{u_h})
	%\label{eq:nonlinMatrixFormulation}
%\end{align}
%%
%In order to solve this nonlinear system of equations I used newton iterations which can be divided into three steps 
%%
%\begin{enumerate}
	%\item $r^k = \mathcal{ F } (\mathbf{u_h}^k) - \mathcal{A}\mathbf{u_h}^k$   , Calculating the residual
	%\item $\hat{e}^k = \mathcal{J}_k^{-1}r^k $  , Calculating the error 
	%\item $\mathbf{u_h}^{k+1}=\mathbf{u_h}^k+\hat{e}^k$    , updating the solution
%\end{enumerate}
%%
%Where $\mathcal{J}_k$ is the jacobian matrix of $\mathcal{F}(\mathbf{u_h}^k)$

%\colorbox{blue}{mention the fact that LS formulation leads to a non-linear loading function}

%\colorbox{red}{How to deal with boundary conditions \ldots }
