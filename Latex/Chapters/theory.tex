% Chapter 1 - THEORY

\chapter{Theory} % Main chapter title

\label{chap:theory} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 1. \emph{Established theory}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------

\section{Informal introduction to least-squares}
The least-squares method is a numerical method with similarities to mixed Galerkin. However it has a fundamentally different approach regarding the definition of the bilinear functional. The following theory is mostly assembled from Jiang \cite{Jiang}. 

Let us look at a system of first order differential equations on the form 
\begin{align}
	Au &= f \text{ in } \Omega \\
	u &= g \text{ on } \partial \Omega.
	\label{eq:PDE}
\end{align}
Where $A$ is a partial differential operator defined as 
\begin{align}
	A = \sum_{i = 1}^{n} A_i\frac{\partial}{\partial x_i} + A_0.
	\label{def:operatorA}
\end{align}
	$n$ being the number of dimensions of the domain $\Omega$. If $u$ happens to be a vector function of say $k$ dimensions then $A_i$ will be a matrix with $k$ columns and $k$ or more rows. Let us initially assume without loss of generality that $g=0$ . Further we require $f \in L_2(\Omega)$ and choose $V = \left\{ v\in L_2(\Omega) | v = 0 \text{ on } \partial \Omega \right\}$. A residual is defined
\begin{align}
	R(v) = Av-f,
	\label{eq:Residual}
\end{align}
and a functional
\begin{align}
	 J(v) = \frac{1}{2}||R(v)||^2_0.
	\label{eq:Functional}
\end{align} 
The solution $u$ and it's gradient needs to be in $L^2$ for the functional to make sense, hence $u$ is restricted to the space $H^1_0(\Omega)$. The homogeneous boundary condition is now included in the definition of the search space. By minimizing $J$ we obtain 
\begin{align}
	\lim_{t\rightarrow 0} \frac{d}{dt}J(u+tv) = \int_{\Omega}(Av)^T(Au-f)d\Omega = 0 \text{    ,   } \forall v \in V.
	\label{eq:minProb}
\end{align}
We can now write a variational formulation of the least-squares method: Find $u \in V$ such that 
\begin{align}
	Q(u,v) = F(v) \; \; \; , \; \; \; \forall v \in V,
	\label{def:varForm}
\end{align}
where
\begin{align}
	Q(u,v) = (Au,Av), \\
	F(v) = (f,Av).
	\label{def:bilin}
\end{align}
Notice that the bilinear form $Q$ is symmetric, this is an important advantage least-squares has over other projection methods. The bilinear form that surged from a first-order problem by the least-squares leads us to a variational formulation similar to the one obtained from a second order problem by the Galerkin method. Basically the bilinear form from least-squares will correspond to a bilinear form of a problem of twice the order obtained using standard Galerkin. In order to avoid problems of large complexity a higher order PDE should therefore be transformed to a system of first order PDE's (similar to a mixed Galerkin approach) before defining the least squares functional.
%In order to apply a numerical algorithm the domain $\Omega$ needs to be discretized, we name this discretization $\Omega_h$. A set of basis functions $ \left\{ N \right\}_i $ is defined for $V_h = H^1_0(\Omega_h)$ such that the discrete variational formulation can be stated. Find $u_h \in V_h$ such that 
%\begin{align}
	%Q(u_h,v_h) = F(v_h) \; \; \; , \; \; \; \forall v_h \in V_h,
	%\label{def:varForm}
%\end{align}

\section{Formal formulation of least-squares}
The formulation stated in this section is a short summary of Bochev and Gunzburger~\cite{Bochev}.
Let us look at a general boundary value problem where $f \in Y(\Omega)$, $g \in B(\partial \Omega)$, $\mathcal{B}\colon X(\partial \Omega) \to B(\partial\Omega) $ and $\mathcal{L}\colon X(\Omega)\to Y(\Omega)$. Find $u \in X(\Omega) $ such that 
\begin{align}
	\begin{split}
	\mathcal{L} u &= f \; \; \; \text{ in } \Omega \\
	\mathcal{B}u &= g \; \; \; \text{ on } \partial \Omega.
	\end{split}
	\label{eq:BVP}
\end{align}
Whenever this BVP has a unique solution, a least-squares functional can be defined as 
\begin{align}
	J(u;f,g) = ||\mathcal{L}u-f||^2_Y + ||\mathcal{B}u-g||^2_B
	\label{eq:FunctionalGen}
\end{align}
and the corresponding minimization problem is then given as 
\begin{align}
	\min_{u \in X}J(u;f,g).
	\label{eq:minProbGen}
\end{align}
Now, for any well-posed problem $\exists \: \alpha,\beta > 0$ such that 
\begin{align}
	\alpha||u||_X^2 \leq J(u;0,0) = (\mathcal{L}u,\mathcal{L}u)_Y+(\mathcal{B}u,\mathcal{B}u)_B \leq \beta||u||_X^2.
	\label{eq:normEq}
\end{align}
The fact that our functional is norm-equivalent is of crucial importance to a successful LS-method. It is therefore important that the spaces $X,Y \text{ and } B$ are chosen such that the LS-functional defines a norm which is equivalent to $|| \cdot ||_X$.
Minimizing this functional is equivalent to solving the Euler-Lagrange equations formulated as 
\begin{align}
	\text{find } u \in X \text{  such that  } Q(u,v) = F(v) \; \; \forall v\in X
	\label{eq:varFormGen}
\end{align}
Where $Q(u,v)$ and $F(v)$ are defined as 
\begin{align}
	\begin{split}
	Q(u,v) &= (\mathcal{L}u,\mathcal{L}v)_Y+(\mathcal{B}u,\mathcal{B}v)_B, \\
	F(v) &= (f,\mathcal{L}v)_Y+(g,\mathcal{L}v)_B.
	\end{split}
	\label{eq:VarFormLinForms}
\end{align}
%
Notice that $Q(u,v)$ defines an inner product and $Q(u,u)^{1/2}=J(u;0,0)^{1/2}$ defines the corresponding norm, which we will name the \textit{energy norm},

\begin{align}
	||| u ||| := Q(u,u)^{1/2}
	\label{eq:energynorm}
\end{align}

In order to solve the BVP numerically we define discrete function spaces $X^h \subset X, \; Y^h\subset Y \; \text{ and } B^h \subset B $ and the corresponding variational formulation is then written as 
\begin{align}
	\text{find } u^h \in X^h \text{  such that  } Q(u^h,v^h) = F(v^h) \; \; \forall v^h\in X^h.
	\label{eq:varFormGenDisc}
\end{align}
%
\section{Error analysis}
Let $u$ be the analytical solution of a problem of the type\eref{eq:BVP}, $u^h$ is our numerical solution to\eref{eq:varFormGenDisc} and $u^h_{\perp} $ is the orthogonal projection of $u$ in $X_h$ \cite{bochev1998}. 
\begin{align}
	\begin{split}
	Q(u-u^h,u-u^h) &= Q(u-u^h,u-u^h_{\perp}) + Q(u-u^h,u^h_{\perp}-u^h) \\
							   &= Q(u-u^h,u-u^h_{\perp}) \\
							 	 &\leq \beta ||u-u^h||_{X_h} \; ||u-u^h_{\perp}||_{X_h}.
	\end{split}
	\label{eq:error1}
\end{align}
The first equality is due to adding and subtracting $u^h_{\perp}$, because both $u^h$ and $u^h_{\perp}$ solves the variational formulation we can cancel the last term, and by using the norm-equivalency from\eref{eq:normEq} and Schwartz inequality we get the last  expression. Now by applying the first inequality of\eref{eq:normEq} we end up with 
\begin{align}
	||u-u^h||_{X_h}\leq \frac{\beta}{\alpha}||u-u^h_{\perp}||_{X_h} = \min_{w^h \in X_h}\frac{\beta}{\alpha}||u-w^h||_{X_h}.
	\label{error_final}
\end{align}
The error is reduced to a pure interpolation problem in the same way as with a standard Galerkin method. 

An important consequence of this result is that with spectral basis functions one can obtain spectral convergence, 
\begin{align}
	||u-u^h||_{L_2(\Omega)} \leq c_0N^{-\sigma}||u||_{H^{\sigma}(\Omega)}.
	\label{eq:spectralConvergence}
\end{align}
Where $N$ is the polynomial order of the basis functions.
Proof can be found in Canuto and Quarteroni \cite{Canuto}.
%

\section{Least squares applied on some common PDE's}
Before we start elaborating to much on each test case, I will provide a quick overview of the problems investigated in this project. All of them are BVP with either Neumann or Dirichlet boundary conditions, the results can be found in chapter~\ref{chap:results}. The problems solved in this project are simply expansions of the Poisson equation,  
%
\begin{align}
	-\Delta u = f \text{  in  } \Omega.
	\label{eq:PossionImplementation}
\end{align}
%
Then by adding a transport term you obtain the diffusion transport equation
%
\begin{align}
	-\mu \Delta u + \mathbf{b} \cdot \nabla u = f \text{ in } \Omega.
	\label{eq:DiffTransImplementation}
\end{align}
%
This can be further expanded by adding a reaction term
%
\begin{align}
	-\mu \Delta u + \mathbf{b} \cdot \nabla u +\sigma u = f \text{ in } \Omega.
	\label{eq:ReactionImplementation}
\end{align}
%
And as a final complication the vector field $\mathbf{b}$ can be made dependent on $u$ and we end up with the nonlinear diffusion transport reaction equation
%
\begin{align}
	-\mu \Delta u + \mathbf{b}(u) \cdot \nabla u +\sigma u = f \text{ in } \Omega.
	\label{eq:ReactionImplementation}
\end{align}
%
By defining $\mathbf{w}=-\nabla u$, and $ \mathbf{u} = \mathbf{w} \oplus u $, all the equations listed above are transformed into a first order system of PDE's 
%
\begin{align}
	\mathcal{L}\mathbf{u} = \mathbf{f}.
	\label{eq:genFirstOrderFormulation}
\end{align}
%
We will now investigate the partial differential operator $\mathcal{L}$ for each of the mentioned problems.
%

\subsection{Poisson problem}

The Poisson problem is defined as 
\begin{align}
	-\Delta u = f \text{ in } \Omega \\
	u = g \text{ on } \partial \Omega
	\label{eq:Poisson}
\end{align}
Let us first consider the homogeneous case. The straight forward least-squares approach is to define $\mathbf{w} = -\nabla u$ and solve the system of equations 
\begin{align}
	\mathbf{w} + \nabla u = 0 \text{ in } \Omega \\
	\nabla \cdot \mathbf{w} = f \text{ in } \Omega \\
	u = 0 \text{ on } \partial \Omega
	\label{eq:PoissonSystem}
\end{align}
which can be written in the same form as\eref{eq:BVP} with $ \mathbf{u} = \mathbf{w} \oplus u $, $\mathbf{f} = [0,0,f]$, $g=0$, $\mathcal{B} = [0,0,1]^T $ and $\mathcal{L}$ given as 
\begin{align}
	\mathcal{L} =
	\begin{bmatrix}
		1 & 0 & \frac{\partial} {\partial x}  \\
		0 & 1 & \frac{\partial} {\partial y}  \\
    \frac{\partial} {\partial x} & \frac{\partial} {\partial y} & 0 
	\end{bmatrix}
	\label{eq:Amatrix}
\end{align}
We define the search space $X =  H^1(\Omega;\text{div}) \times H_0^1(\Omega)$ and the solution space $Y \cup  B  = [L^2(\Omega)]^3\cup L^2(\partial \Omega) $. The functional defined in\eref{eq:FunctionalGen} will for our problem be 
\begin{align}
	J(u;f) = ||\mathcal{L}u-f||^2_Y.
	\label{eq:lsFunctionalPoisson}
\end{align}
The term corresponding to the boundary conditions is imposed directly in the definition of our search space and is therefore not included in our functional as implied by equation\eref{eq:FunctionalGen}. We will later show that this results in a better numerical solution. The corresponding variational formulation with functionals defined in\eref{eq:VarFormLinForms} can now be stated. Find $ \mathbf{u} \in X $ such that
\begin{align}
	Q(\mathbf{u},\mathbf{v}) = F(\mathbf{v}) \;\; \forall \;\; \mathbf{v} \in X.
	\label{eq:VariationalFormulationPoisson}
\end{align}
For the equations to be valid we require that $\mathbf{f} \in Y$.
Notice that the spaces $X$ and $Y$ chosen as described above fulfill the condition\eref{eq:normEq} due to~\cite{Bochev}. 
%
\subsection{Diffusion transport reaction problem}
%
The diffusion transport reaction problem to be analyzed is given as 
\begin{align}
	-\mu \Delta u + \mathbf{b} \cdot \nabla u +\sigma u = f \text{ in } \Omega \\
	u = g \text{ on } \partial \Omega
	\label{eq:DiffTrans}
\end{align}
where $ \mu$ is the diffusion constant, $\mathbf{b} = [b_1 , b_2]$ is a vector field and $\sigma$ is some reaction constant. By following the same approach as for the Poisson problem we end up with $\mathcal{L}$ on the form
\begin{align}
	\mathcal{L} =
	\begin{bmatrix}
		1 & 0 & \frac{\partial} {\partial x}  \\
		0 & 1 & \frac{\partial} {\partial y}  \\
		\mu \frac{\partial} {\partial x} - b_1 & \mu \frac{\partial} {\partial y} -b_2 & \sigma
	\end{bmatrix}
	\label{eq:AmatrixDiff}
\end{align}
which leads to a similar but slightly different linear system than the one created by the Poisson problem.

%The straight forward least-squares approach is to define $\mathbf{w} = -\nabla u$ and solve the system of equations \begin{align}
	%\mathbf{w} + \nabla u = 0 \text{ in } \Omega \\
	%\nabla \cdot \mathbf{w} - b \cdot \mathbf{w} = f \text{ in } \Omega \\
	%u = 0 \text{ on } \partial \Omega.
	%\label{eq:DiffTransSystem}
%\end{align}
%which can be written in the same form as ~\eref{eq:BVP} with $ \mathbf{u} = \mathbf{w} \oplus u $, $\mathbf{f} = (0,0,f)$, g = 0, $\mathcal{B} = (0,0,1)^T $ and L given as 
%\begin{align}
	%\mathcal{L} =
	%\begin{bmatrix}
		%1 & 0 & \partial / \partial x  \\
		%0 & 1 & \partial / \partial y  \\
		%\partial / \partial x - b_1 & \partial/ \partial y -b_2 & 0
	%\end{bmatrix}
	%\label{eq:AmatrixDiff}
%\end{align}
%We define the search space $X =  H^1(\Omega;\text{div}) \times H_0^1(\Omega)$ and the solution space $Y \times B  = [L^2(\Omega)]^3\times L^2(\Omega) $ and the functional can then be defined as in~\eref{eq:FunctionalGen}. The variational formulation of the problem can be stated. Find $ \mathbf{u} \in X $ s.t.
%\begin{align}
	%Q(\mathbf{u},\mathbf{v}) = F(\mathbf{v}) \;\; \forall \;\; \mathbf{v} \in X.
	%\label{eq:VariationalFormulationPoisson}
%\end{align}
%We require that $\mathbf{f} \in Y$.
%Notice that the spaces $X$ and $Y$ chosen as described above fullfill the condition ~\eref{eq:normEq}. 

\subsection{Nonlinear problem}
Now let the vector field $\mathbf{b}$ from the diffusion transport reaction problem be a function of $u$. 
\begin{align}
	-\mu \Delta u + \mathbf{b}(u) \cdot \nabla u +\sigma u = f \text{ in } \Omega \\
	u = g \text{ on } \partial \Omega
	\label{eq:DiffTransNonLin}
\end{align}
This gives us a nonlinear variational formulation that does not allow us to solve our system of equations directly. In order to find a solution Newtons method was used. A notable difference between standard Galerkin and least-squares is that the linear functional $F(\cdot)$ will also be non-linear in the LS case.
%Needs to add the Jacobian of $F$ as well since this depends on $b$ and thus also $u$. 
%%
%Let us consider the diffusion transport equation with non-homogeneous boundary conditions and a non-linear gradient term with a LS-approach. This corresponds to solving the equation 
%\begin{align}
	%Q(\tilde{\mathbf{u}},\mathbf{v};b) &= \tilde{F}(\mathbf{v};b) \\
	%Q(\tilde{\mathbf{u}},\mathbf{v};b) - \tilde{F}(\mathbf{v};b) &= 0\\
	%\mathcal{F}(\tilde{\mathbf{u}},\mathbf{v};b) &= 0
	%\label{eq:varFormNonLin}
%\end{align}
%%
%Where the Dirichlet homogeneous boundary conditions on $\tilde{\mathbf{u}}$ are required by the search space.
%Newtons method is then applied, you start by guessing an initial $\tilde{\mathbf{u}}_h^0$ and then repeating
%%
%\begin{enumerate}
	%\item $r^k = \mathcal{ F } (\tilde{\mathbf{u}}_h^k)$  , Calculating the residual
	%\item $\hat{e}^k = \mathcal{J}_k^{-1}r^k $  , Calculating the error 
	%\item $\tilde{\mathbf{u}}_h^{k+1}=\tilde{\mathbf{u}}_h^k-\hat{e}^k$    , updating the solution
%\end{enumerate}
%%
%until you reach your solution. $\mathcal{J}_k$ is the Jacobian matrix of $\mathcal{F}(\mathbf{u_h}^k)$.
\section{Boundary conditions} \label{BC}
Imposing the boundary conditions in a least squares setting can either be done by creating a lifting function and in this way imposing them by restricting our search space, or it can be added to our functional as implied by formula \eref{eq:FunctionalGen}. In this section these two techniques will be clarified. 
\subsection{non-homogeneous Dirichlet boundary conditions}
If $g \neq 0$ then we can simply define a lifting function $R_g \in X$ such that $R_g(\partial \Omega) = g(\partial \Omega)$. By defining $\tilde{\mathbf{u}}=\mathbf{u}-R_g$ we can replace this for $\mathbf{u}$ in the variation formulation and get 
\begin{align}
	Q(\tilde{\mathbf{u}}+R_g,\mathbf{v}) &= F(\mathbf{v}) \\
	Q(\tilde{\mathbf{u}},\mathbf{v})+Q(R_g,\mathbf{v}) &= F(\mathbf{v}) \\
	Q(\tilde{\mathbf{u}},\mathbf{v}) &= F(\mathbf{v}) - Q(R_g,\mathbf{v})\\
	Q(\tilde{\mathbf{u}},\mathbf{v}) &= \tilde{F}(\mathbf{v}).
	\label{eq:liftingFunc}
\end{align}
%
This way the test functions and the solution are in the same space, i.e. $\mathbf{\tilde u}, \mathbf{v} \in X_0$.
\subsection{non-homogeneous Neumann boundary conditions}
Because of the geometry of our problem and the fact that we define the flux as an extra variable, we can transform the Neumann conditions to a Dirichlet condition on the flux. 
\begin{align}
	\frac{\partial u}{\partial \mathbf{n}} &= h \text{  on   } \partial \Omega \\
	\nabla u \cdot \mathbf{n} &= h \\
	 \mathbf{w} \cdot \mathbf{n} &= -h. 
	\label{eq:neumann}
\end{align}
Let us define $\hat{x}$ and $\hat{y}$ as the unit vectors in each direction. Notice that for the west ($x=0$) and east ($x=1$) edges the normal vector $\mathbf{n}= \pm\hat{x}$, and at the north ($y=1$) and south($y=0$) edges $\mathbf{n}=\pm \hat{y}$. This way we can write the Neumann conditions as a Dirichlet condition on the first and second component of $\mathbf{w}= [ w_1 \:,\: w_2]$. 
\begin{align}
	w_1 = \pm h \text{    for $x = 0$ and $x=1$ }\\
	w_2 = \pm h \text{    for $y = 0$ and $y=1$ }
	\label{eq:neumannAsDirichlet}
\end{align}
\subsection{Boundary conditions as an additional functional}
The boundary conditions can also be implemented as the functional described in equation \eref{eq:FunctionalGen}. For a BVP with Dirichlet BC's this will correspon to adding $||u-g||^2_0$ to our functional $J$. By minimizing this term we end up with the following contribution to the variational form
\begin{align}
	(u,v)_{\partial \Omega}=(g,v)_{\partial \Omega}
	\label{eq:BCFunctionalImplementationContribution}
\end{align}
Similarly for a BVP with Neumann boundary conditions on $\Gamma_N$ and Dirichlet conditions on $\Gamma_D$ the contribution to the functional will be
\begin{align}
	(u,v)_{\Gamma_D} + (\mathbf{n}\cdot \mathbf{w},v)_{\Gamma_N}=
	(g_D,v)_{\Gamma_D} + (g_N,v)_{\Gamma_N} 
	\label{eq:NeuDirFunctional}
\end{align}
